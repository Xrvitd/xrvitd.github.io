<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="MeshMosaic: Scaling Artist Mesh Generation via Local-to-Global Assembly">
  <meta name="keywords" content="3D Mesh Generation, Autoregressive, Local-to-Global, Boundary Condition, Point Cloud">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MeshMosaic</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://xrvitd.github.io" crossorigin>
  <meta property="og:type" content="website">
  <meta property="og:title" content="MeshMosaic: Scaling Artist Mesh Generation via Local-to-Global Assembly">
  <meta property="og:description" content="MeshMosaic scales artist-designed meshes to 100K+ triangles via local-to-global assembly of boundary-conditioned patches, preserving fine details and controllable density.">
  <meta property="og:image" content="https://xrvitd.github.io/images/title.png">
  <meta property="og:url" content="https://xrvitd.github.io/">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="MeshMosaic: Scaling Artist Mesh Generation via Local-to-Global Assembly">
  <meta name="twitter:description" content="Local-to-global assembly of boundary-conditioned patches; 100K+ triangles with fine details.">
  <meta name="twitter:image" content="https://xrvitd.github.io/images/title.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">

  <link rel="stylesheet" href="styles.css">
</head>

<body>

  <!-- Top logos -->
  <section>
    <div class="container is-max-desktop">
      <div class="logo-strip">
        <img src="https://xrvitd.github.io/images/Logo_HKU.png" alt="The University of Hong Kong (HKU)" loading="lazy">
        <img src="https://xrvitd.github.io/images/Logo_tencent.png" alt="Tencent Visvise" loading="lazy">
        <img src="https://xrvitd.github.io/images/UST.svg" alt="Hong Kong University of Science and Technology (HKUST)" loading="lazy">
        <img src="https://xrvitd.github.io/images/Emblem_motto_name_MUST_logo.png" alt="Macau University of Science and Technology (MUST)" loading="lazy">
        <img src="https://xrvitd.github.io/images/Logo_SDU.png" alt="Shandong University (SDU)" loading="lazy">
        <img src="https://xrvitd.github.io/images/Logo_TAMU.png" alt="Texas A&M University (TAMU)" loading="lazy">
      </div>
    </div>
  </section>

  <!-- Side navigation -->
  <div class="side-nav" aria-label="section navigation">
    <a href="#home">Home</a>
    <a href="#abstract">Abstract</a>
    <a href="#method">Method</a>
    <a href="#results">Results</a>
    <a href="#BibTeX">BibTeX</a>
  </div>

  <section class="hero" id="home">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><img src="https://xrvitd.github.io/images/title.png" alt="MeshMosaic" style="height:70px; vertical-align:-6px;" loading="lazy">: Scaling Artist Mesh Generation via Local-to-Global Assembly</h1>
            <div class="is-size-5 publication-authors">
              <div class="is-size-8">
                <span class="author-block"><a href="https://ruixu.me/" target="_blank">Rui Xu</a><sup>1</sup>,</span>
                <span class="author-block"> <a href="https://xty.im/" target="_blank">Tianyang Xue</a><sup>1</sup>,</span>
                <span class="author-block"> <a href="https://qiujiedong.github.io/" target="_blank">Qiujie Dong</a><sup>1</sup>,</span>
                <span class="author-block"> <a href="#" target="_blank">Le Wan</a><sup>2</sup>,</span>
                <span class="author-block"> <a href="https://scholar.google.com/citations?user=pM4ebg0AAAAJ&hl=en" target="_blank">Zhe Zhu</a><sup>2</sup>,</span>
                <span class="author-block"> <a href="https://penghtyx.github.io/yuki-lipeng" target="_blank">Peng Li</a><sup>3</sup>,</span>
                <span class="author-block"> <a href="https://frank-zy-dou.github.io/" target="_blank">Zhiyang Dou</a><sup>1</sup>,</span> <br>
                <span class="author-block"> <a href="https://clinplayer.github.io/" target="_blank">Cheng Lin</a><sup>4</sup>,</span>
                <span class="author-block"> <a href="https://irc.cs.sdu.edu.cn/~shiqing/index.html" target="_blank">Shiqing Xin</a><sup>5</sup>,</span>
                <span class="author-block"> <a href="https://liuyuan-pal.github.io/" target="_blank">Yuan Liu</a><sup>3&dagger;</sup>,</span>
                <span class="author-block"> <a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html" target="_blank">Wenping Wang</a><sup>6</sup>,</span>
                <span class="author-block"> <a href="https://www.cs.hku.hk/index.php/people/academic-staff/taku" target="_blank">Taku Komura</a><sup>1&dagger;</sup></span>
              </div>
              <div class="is-size-7" style="margin-top:8px;">
                <sup>1</sup>The University of Hong Kong,
                <sup>2</sup>Tencent Visvise,
                <sup>3</sup>Hong Kong University of Science and Technology,<br>
                <sup>4</sup>Macau University of Science and Technology, 
                <sup>5</sup>Shandong University,
                <sup>6</sup>Texas A&amp;M University
                <div>(&dagger; Corresponding authors.)</div>
              </div>
              <div class="is-size-6" style="margin-top:6px; font-weight:600;">Arxiv Preprint.</div>
            </div>

            <div class="publication-links">
              <a href="main.pdf" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                <span class="icon"><i class="fa-regular fa-file-pdf"></i></span>
                <span>Paper</span>
              </a>
              <a href="https://github.com/Xrvitd/MeshMosaic" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </div>
          </div>
        </div>

        <div class="columns is-centered" style="margin-top:18px;">
          <div class="column is-full has-text-centered">
            <video class="fig-video" src="https://xrvitd.github.io/images/show.mp4" autoplay muted loop playsinline preload="metadata"></video>
            <div class="caption">MeshMosaic empowers scaling up artist mesh generation to more than 100k triangles by assembling boundary-conditioned local patches into cohesive, high-resolution meshes. It delivers flexible support over mesh density and ensures the faithful retention of intricate design details. Faces are assigned random blue colors to better illustrate the mesh layout.</div>
          </div>
        </div>

      </div>
    </div>
  </section>

  <!-- Abstract -->
  <section class="hero is-light is-small" id="abstract">
    <div class="container is-max-desktop">
      <h2 class="title is-4 center">Abstract</h2>
      <div class="content has-text-justified">
        <p>
          Scaling artist-designed meshes to high triangle numbers remains challenging for autoregressive generative models. Existing transformer-based methods suffer from long-sequence bottlenecks and limited quantization resolution, primarily due to the large number of tokens required and constrained quantization granularity. These issues prevent faithful reproduction of fine geometric details and structured density patterns.
          We introduce MeshMosaic, a novel local-to-global framework for artist mesh generation that scales to over 100K trianglesâ€”substantially surpassing prior methods, which typically handle only around 8K faces. MeshMosaic first segments shapes into patches, generating each patch autoregressively and leveraging shared boundary conditions to promote coherence, symmetry, and seamless connectivity between neighboring regions.
          This strategy enhances scalability to high-resolution meshes by quantizing patches individually, resulting in more symmetrical and organized mesh density and structure.
          Extensive experiments across multiple public datasets demonstrate that MeshMosaic significantly outperforms state-of-the-art methods in both geometric fidelity and user preference, supporting superior detail representation and practical mesh generation for real-world applications.
        </p>
       
      </div>
    </div>
  </section>

  <!-- Method / Pipeline -->
  <section class="section" id="method">
    <div class="container is-max-desktop">
      <h2 class="title is-3 center">Method</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <div class="video-cropper">
            <video class="fig-video" src="https://xrvitd.github.io/images/pepiline.mp4" autoplay muted loop playsinline preload="metadata"></video>
          </div>
          <div class="caption">The pipeline of MeshMosaic: Local-to-global assembly with semantic patching and boundary conditioning.</div>
        </div>
      </div>
      <div class="content has-text-justified">
        <p>
          During inference, our method first applies PartField to obtain semantic segmentation of the input shape. The input point cloud is then sampled
according to the segmented patches and the original shape. Finally, our approach produces a clean, highly detailed mesh by assembling the generated patches.
        </p>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 center">Train on Single Patch</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">

          <video class="fig-video" src="https://xrvitd.github.io/images/train.mp4" autoplay muted loop playsinline preload="metadata"></video>

          <div class="caption">The workflow of MeshMosaic for generating a single patch.</div>
        </div>
      </div>
      <div class="content has-text-justified">
        <p>
          Both global and local point
cloud features are extracted by a locked Michelangelo encoder. For each patch,
the nearest boundary mesh is identified, tokenized, and concatenated before the target mesh token
sequence. The GRU network encodes boundary tokens, which are then combined with global and
local features and fed into an autoregressive hourglass transformer for mesh generation.
        </p>
      </div>
    </div>
  </section>

  <!-- Comparisons -->
  <section class="section" id="results">
    <div class="container is-max-desktop">
      <h2 class="title is-3 center">Comparisons</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <video class="fig-video" src="https://xrvitd.github.io/images/comp.mp4" autoplay muted loop playsinline preload="metadata"></video>
          <div class="caption">Visual comparison of MeshMosaic with state-of-the-art methods.</div>
        </div>
      </div>
    </div>
  </section>
  <!-- Face -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 center">High-resolution Face Numbers</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <video class="fig-video" src="https://xrvitd.github.io/images/facecnt.mp4" autoplay muted loop playsinline preload="metadata"></video>
          <div class="caption">Visual comparison of MeshMosaic with state-of-the-art methods.</div>
        </div>
    </div>
    <div class="content has-text-justified">
      <p>
        We present a more compelling example. For a complex fighter jet model, our method successfully reconstructs intricate details using nearly 30K triangles whereas other approaches struggle with such highly complex shapes, typically yielding only a few hundred to a few thousand triangles. This noticeable gap demonstrates the superior detail recovery and scalability of our method with substantially higher triangle counts.
      </p>
  </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 center">More Patches</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <video class="fig-video" src="https://xrvitd.github.io/images/boom.mp4" autoplay muted loop playsinline preload="metadata"></video>
          <div class="caption">MeshMosaic on hundreds of patches.</div>
        </div>
      </div>
      <div class="content has-text-justified">
        <p>
          Although our training set contains no more than sixty splits per instance, our method can handle inference tasks involving hundreds of patches during testing. This highlights the strong generalization capability of our method.
        </p>
    </div>
    </div>
  </section>
  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-4">BibTeX</h2>
      <p>We will release an official BibTeX entry. </p>
      <!-- <pre><code>@misc{meshmosaic2026,
  title = {MeshMosaic: Scaling Artist Mesh Generation via Local-to-Global Assembly},
  author = {Xu, Rui and Xue, Tianyang and Dong, Qiujie and Wan, Le and Zhu, Zhe and Li, Peng and Dou, Zhiyang and Lin, Cheng and Xin, Shiqing and Liu, Yuan and Wang, Wenping and Komura, Taku},
  year = {2026},

}</code></pre> -->

    </div>
  </section>

  

</body>

</html>

